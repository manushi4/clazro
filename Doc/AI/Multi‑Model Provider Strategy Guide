1. Purpose

This guide defines how Clazro selects, routes, and governs multiple AI model providers (OpenAI/ChatGPT, Anthropic/Claude, Google/Gemini, AWS Bedrock, etc.) across tenants, roles, and audience profiles—without refactoring app UI or locking the product to one vendor.

This guide works with:

AI & Automation Architecture Overview (Gateway-first, config-driven execution)

AI Product Scope, Principles & Quality Bar (safety + trust requirements)

Audience Profiles & Experiences (Kid/Teen/Adult/Coaching behavior)

Child Safety, Parental Controls & Age Gating (non-negotiable restrictions)

AI Use-Case Catalog & Feature Matrix (feature-by-feature access + limits)

2. Goals

Vendor independence (swap/upgrade providers without touching UI/features)

Best-model-per-job (reasoning vs summarization vs structured extraction vs multimodal)

Profile-aware safety (Kid profile is stricter than Coaching)

Operational resilience (fallback when a provider is down or degraded)

Cost control (budgets, throttles, caching, and tiered models)

Governance (Platform Studio controlled + auditable + rollback)

3. Definitions

Provider: Vendor platform (OpenAI, Anthropic, Google, AWS Bedrock, etc.)

Model: A specific model offering within a provider (versioned)

Capability Class: What the feature needs (chat, summarization, extraction, reasoning, vision, etc.)

Routing Policy: Rules that choose a provider/model at runtime

Fallback Policy: Rules that choose alternatives on failure

Pinned Model: A fixed model version used for stability (vs “latest”)

Safety Wrapper: Your own policy layer applied regardless of provider (age rules, refusals, redaction)

4. Strategy: Provider-Agnostic by Design
4.1 Mandatory architectural rule

The app never calls providers directly.
All calls go through the AI & Automation Gateway, which enforces:

tenant + role + audience profile policies

prompt governance + safety wrapper

model routing + fallbacks

logging + audit + budgets

4.2 Provider abstraction contract (single internal interface)

All providers must map into one internal contract:

ModelRequest

tenantId, userId, role, audienceProfile

featureId, widgetId

capabilityClass

messages / input

contextBundle (already redacted)

outputMode (free text / strict JSON / schema)

toolsAllowed (none / limited / allowed list)

latencySLA, budgetPolicy, safetyPolicyVersion

ModelResponse

output

structuredOutput (if schema enforced)

refusalReason (if refused)

safetyFlags

provider/model

tokens/cost/latency

traceId

5. Capability Classes and “Best Fit” Routing

Different AI features need different strengths. Route by capability class, not brand.

5.1 Capability classes you must support

SAFE_GUIDED_CHAT (Kid-safe, short, constrained)

GENERAL_CHAT (Teen/Adult conversational)

DEEP_REASONING (Coaching copilot, planning, complex tasks)

SUMMARIZATION (meeting/class summary, digests)

STRUCTURED_EXTRACTION (JSON, forms, checklists, rubric outputs)

CLASSIFICATION (topic detection, safety labels, intent)

MULTIMODAL_VISION (image understanding, if needed)

EMBEDDINGS / RETRIEVAL (semantic search, RAG)

IMAGE_GENERATION (if you support it—separate governance)

5.2 Default routing philosophy

Use cheaper/faster models for summarization, classification, extraction

Use stronger reasoning models only for features that truly require it

For kids: prioritize safety + simplicity, not creativity

6. Audience Profile Routing Rules

Audience profile rules override everything.

6.1 Kid profile

Only allow: SAFE_GUIDED_CHAT, SUMMARIZATION (restricted), CLASSIFICATION

Deny: autonomous tool use, deep reasoning loops, open-ended generation

Always apply:

stricter safety wrapper

shorter max response length

more conservative refusals

parent/coach visibility requirements

6.2 Teen profile

Allow structured chat + learning assistance

Tool use only with explicit confirmation (and limited scopes)

Higher refusal sensitivity than adults

6.3 Adult profile

Allow broader features, including tool-assisted workflows (if consented)

Cost controls and privacy still enforced

6.4 Coaching profile

Allow deepest reasoning + drafting + tool-assisted workflows

Human-in-the-loop by default for sensitive actions

Full auditability required

7. Tenant-Level Model Strategy

Each tenant may vary by:

budget

latency expectations

compliance needs / region

safety strictness

feature set enabled

Tenant knobs (configurable in Platform Studio)

enabledProviders[]

allowedCapabilityClasses[]

maxCostPerDay, maxCostPerUser, maxCostPerFeature

latencySLA

dataRetentionPolicy

toolAllowlists

approvalRequirements (e.g., coach review required)

Rule: Tenant config can be stricter than global defaults, never looser than child safety rules.

8. Routing Policy Design
8.1 Routing inputs

Routing must consider:

featureId + capabilityClass

audienceProfile

tenant tier (budget plan)

region/compliance (if applicable)

current provider health (timeouts/error rate)

required output mode (schema/JSON reliability)

toolsAllowed (provider compatibility)

8.2 Routing outputs

Primary: provider/model

Secondary fallback list: 1–3 alternatives

Execution parameters: temperature, max tokens, JSON mode, tool enablement

8.3 Example routing rule (conceptual)

If audienceProfile == Kid → route only to “KidSafeTier” models + strict templates

If capabilityClass == SUMMARIZATION → route to low-cost summarizer model

If capabilityClass == DEEP_REASONING and role == Coach → route to strongest reasoning model

If provider health is degraded → fail over to secondary provider

9. Fallback and Degraded Modes
9.1 Failure types

provider timeout / outage

rate limiting

invalid output format (schema failure)

tool call failure

safety policy violation

9.2 Fallback rules

Retry (limited, jittered)

Switch model within same provider (same capability)

Switch provider (secondary provider)

Degraded response (simpler model / shorter output)

Non-AI fallback UI (safe-mode content, cached summary, or “try again”)

9.3 Hard rule

Fallback must never relax child safety, RBAC, or consent rules.

10. Model Versioning and Change Management
10.1 Pinned versions

Production features must use pinned model versions to reduce output drift.

10.2 Rollout process

Dev/test: experiment freely

Staging: pinned candidate + eval suite

Production: gradual rollout (tenant canary → expand)

Rollback: instant via config switch

10.3 Drift controls

regression evaluation on golden prompts

schema validation pass rate thresholds

safety flag rate thresholds

user satisfaction monitoring

11. Tool Use Compatibility

Tool calling differs across providers. Your Gateway must normalize:

tool schema format

tool call parsing and validation

tool allowlists per feature/profile

tool execution safety rules

For minors: tool use is either disabled or heavily restricted per the Child Safety guide.

12. Data Handling Rules (Provider-Agnostic)

Regardless of provider:

minimize context (only what is needed)

redact PII by policy (kids stricter)

no secrets in prompts

no training on user data (where provider options exist; enforce your policy)

log only what is necessary (with privacy controls)

retain only per retention policy

13. Cost Strategy
13.1 Tiered models per capability

cheap tier: classification, extraction, summaries

standard tier: general chat

premium tier: deep reasoning/coaching copilot (limited access)

13.2 Cost controls

per-tenant budgets

per-feature caps

per-user daily limits

caching for summaries where allowed

truncate context intelligently (RAG, not raw dumps)

14. Quality Bar per Provider

A provider/model may be used in production only if it meets minimum thresholds for the target capability class:

Safety: low unsafe output rate (especially Kid/Teen)

Format reliability: schema/JSON success rate for extraction features

Latency: meets feature SLA

Cost: meets budget targets

Stability: consistent outputs under pinned version

Tool compatibility: works with your tool gateway if required

Providers can be approved per capability class (e.g., “approved for summarization but not tool use”).

15. Required Config Schema (Conceptual)

Your Platform Studio should publish something like:

providers: enabled + credentials references

models: provider → model definitions + tags (cheap/standard/premium)

routingRules[]: conditions → primary model + fallback list

capabilityPolicies: per capability class (max tokens, output mode, tools)

audiencePolicies: kid/teen/adult/coaching constraints

budgets: tenant/feature/user caps

killSwitch: global/tenant/feature flags

16. Adding a New Provider Checklist

Gateway adapter implemented (request/response normalization)

Supports required output modes (text + schema)

Safety wrapper validated (kid/teen)

Observability integrated (tokens/cost/latency/trace)

Included in eval suite + baseline comparison

Routing rules + fallbacks defined

Studio controls added (enable/disable, budgets, approval)

Canary rollout + rollback plan

17. Example “Default Recommendations” (High-Level)

Kids: safest constrained chat + strict refusal behavior, minimal output

Teens: structured chat + learning help, limited tool usage with confirmation

Adults: standard chat + summaries + optional tool flows

Coaches: deeper reasoning models, approved tool access, auditable automations via n8n

(Exact provider/model names remain configurable and pinned per environment.)

18. Non‑Negotiables Summary

Multi-model is controlled by config, not code changes

Safety, RBAC, and consent never change during fallback

Pinned versions + eval-driven rollouts prevent drift

Costs are capped by tenant/feature/user

Tool use is normalized and governed centrally